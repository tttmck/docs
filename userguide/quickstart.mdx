---
title: "快速开始"
description: "5分钟快速上手晨羽智云"
icon: "rocket"
---

# 快速开始

欢迎使用晨羽智云！本指南将帮助您在5分钟内创建并启动您的第一个GPU实例。

## 准备工作

在开始之前，请确保您已经：

<Steps>
  <Step title="注册账户">
    访问 [晨羽智云官网](https://www.chenyu.com) 注册企业账户
  </Step>
  <Step title="获取API Key">
    登录控制台，在"API管理"页面生成您的API密钥
  </Step>
  <Step title="账户充值">
    为您的账户充值至少100元，确保有足够余额创建实例
  </Step>
</Steps>

## 第一步：选择资源

### 1.1 获取可用Pod列表

首先，我们需要查看当前可用的Pod资源：

```bash
curl -X GET "https://api.chenyu.com/v1/pods" \
  -H "Authorization: Bearer YOUR_API_KEY"
```

### 1.2 选择GPU型号

查看指定Pod支持的GPU型号：

```bash
curl -X GET "https://api.chenyu.com/v1/gpu-models?pod_uuid=YOUR_POD_UUID" \
  -H "Authorization: Bearer YOUR_API_KEY"
```

## 第二步：创建实例

使用选定的资源创建您的第一个实例：

<CodeGroup>

```bash cURL
curl -X POST "https://api.chenyu.com/v1/instances" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "pod_uuid": "pod_12345678-1234-1234-1234-123456789012",
    "gpu_model_uuid": "gpu_87654321-4321-4321-4321-210987654321",
    "auto_start": 1
  }'
```

```python Python
import requests

url = "https://api.chenyu.com/v1/instances"
headers = {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json"
}

data = {
    "pod_uuid": "pod_12345678-1234-1234-1234-123456789012",
    "gpu_model_uuid": "gpu_87654321-4321-4321-4321-210987654321",
    "auto_start": 1
}

response = requests.post(url, headers=headers, json=data)
instance_info = response.json()
print(f"实例UUID: {instance_info['data']['instance_uuid']}")
```

</CodeGroup>

## 第三步：监控实例状态

创建实例后，监控其启动状态：

```bash
curl -X GET "https://api.chenyu.com/v1/instances/YOUR_INSTANCE_UUID/status" \
  -H "Authorization: Bearer YOUR_API_KEY"
```

等待实例状态变为 `running` 后，您就可以开始使用了。

## 第四步：连接实例

### 4.1 SSH连接

使用SSH连接到您的实例：

```bash
ssh root@INSTANCE_IP_ADDRESS
```

### 4.2 验证GPU资源

连接成功后，验证GPU是否正常工作：

```bash
nvidia-smi
```

您应该看到类似以下输出：

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:00:04.0 Off |                    0 |
| N/A   30C    P0    53W / 400W |      0MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
```

## 完整示例

以下是一个完整的Python脚本示例，展示如何自动化创建和管理实例：

<CodeGroup>

```python Python SDK
import requests
import time
import json

class ChenyuClient:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://api.chenyu.com/v1"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def get_pods(self):
        """获取可用Pod列表"""
        response = requests.get(f"{self.base_url}/pods", headers=self.headers)
        return response.json()
    
    def get_gpu_models(self, pod_uuid):
        """获取GPU型号列表"""
        params = {"pod_uuid": pod_uuid}
        response = requests.get(f"{self.base_url}/gpu-models", 
                              headers=self.headers, params=params)
        return response.json()
    
    def create_instance(self, pod_uuid, gpu_model_uuid, auto_start=1):
        """创建实例"""
        data = {
            "pod_uuid": pod_uuid,
            "gpu_model_uuid": gpu_model_uuid,
            "auto_start": auto_start
        }
        response = requests.post(f"{self.base_url}/instances", 
                               headers=self.headers, json=data)
        return response.json()
    
    def get_instance_status(self, instance_uuid):
        """获取实例状态"""
        response = requests.get(f"{self.base_url}/instances/{instance_uuid}/status", 
                              headers=self.headers)
        return response.json()
    
    def wait_for_instance_ready(self, instance_uuid, timeout=300):
        """等待实例就绪"""
        start_time = time.time()
        while time.time() - start_time < timeout:
            status = self.get_instance_status(instance_uuid)
            if status['data']['status'] == 'running':
                return True
            elif status['data']['status'] in ['failed', 'error']:
                return False
            time.sleep(10)
        return False

# 使用示例
if __name__ == "__main__":
    # 初始化客户端
    client = ChenyuClient("YOUR_API_KEY")
    
    # 1. 获取可用Pod
    pods = client.get_pods()
    print("可用Pod列表:")
    for pod in pods['data']:
        print(f"- {pod['pod_name']} ({pod['location']})")
    
    # 2. 选择第一个Pod并获取GPU型号
    pod_uuid = pods['data'][0]['pod_uuid']
    gpu_models = client.get_gpu_models(pod_uuid)
    print(f"\n{pods['data'][0]['pod_name']} 支持的GPU:")
    for gpu in gpu_models['data']:
        print(f"- {gpu['gpu_name']} - {gpu['price_per_hour']}元/小时")
    
    # 3. 创建实例
    gpu_model_uuid = gpu_models['data'][0]['gpu_model_uuid']
    result = client.create_instance(pod_uuid, gpu_model_uuid)
    
    if result['code'] == 200:
        instance_uuid = result['data']['instance_uuid']
        print(f"\n实例创建成功！UUID: {instance_uuid}")
        
        # 4. 等待实例就绪
        print("等待实例启动...")
        if client.wait_for_instance_ready(instance_uuid):
            print("✅ 实例已就绪，可以开始使用！")
            
            # 获取实例详细信息
            status = client.get_instance_status(instance_uuid)
            instance_info = status['data']
            print(f"实例IP: {instance_info.get('ip_address', 'N/A')}")
            print(f"SSH连接: ssh root@{instance_info.get('ip_address', 'N/A')}")
        else:
            print("❌ 实例启动失败或超时")
    else:
        print(f"❌ 实例创建失败: {result['message']}")
```

</CodeGroup>

## 常见问题

<AccordionGroup>
  <Accordion title="实例创建失败怎么办？" icon="question">
    1. 检查账户余额是否充足
    2. 确认选择的Pod和GPU型号是否可用
    3. 检查API Key是否正确
    4. 查看错误信息中的具体原因
  </Accordion>
  
  <Accordion title="如何选择合适的GPU型号？" icon="microchip">
    - **A100 80GB**: 适合大规模深度学习训练，内存充足
    - **RTX 4090**: 适合推理和中小规模训练，性价比高
    - **H100**: 最新架构，适合最前沿的AI工作负载
  </Accordion>
  
  <Accordion title="实例启动很慢怎么办？" icon="clock">
    实例启动时间取决于多个因素：
    - 镜像大小：较大的镜像需要更长时间下载
    - 网络状况：网络繁忙时可能影响启动速度
    - 资源可用性：高峰期可能需要等待资源分配
    
    通常实例启动时间在1-3分钟之间。
  </Accordion>
  
  <Accordion title="如何优化成本？" icon="dollar-sign">
    - 及时停止不使用的实例
    - 选择合适的GPU型号，避免过度配置
    - 使用定时开关机功能
    - 监控资源使用情况，避免浪费
  </Accordion>
</AccordionGroup>

## 下一步

恭喜！您已经成功创建并启动了第一个GPU实例。接下来您可以：

<CardGroup cols={2}>
  <Card title="功能介绍" icon="book-open" href="/userguide/introduction">
    深入了解平台的各项功能和最佳实践
  </Card>
  <Card title="API参考" icon="code" href="/api-reference/introduction">
    查看完整的API文档，实现更复杂的自动化
  </Card>
  <Card title="计费说明" icon="credit-card" href="/userguide/billing">
    了解详细的计费规则和成本优化策略
  </Card>
  <Card title="技术支持" icon="headset" href="mailto:support@chenyu.com">
    遇到问题？联系我们的技术支持团队
  </Card>
</CardGroup>

---

<Tip>
  **专业提示** - 建议在正式使用前先创建一个小型实例进行测试，熟悉平台操作后再扩展到生产环境。
</Tip> 